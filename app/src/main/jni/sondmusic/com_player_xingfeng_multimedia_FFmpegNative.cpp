/* DO NOT EDIT THIS FILE - it is machine generated */
#include "com_player_xingfeng_multimedia_FFmpegNative.h"

struct URLProtocol;

/*
 * Class:     com_player_xingfeng_multimedia_FFmpegNative
 * Method:    urlprotocolinfo
 * Signature: ()Ljava/lang/String;
 */
JNIEXPORT jstring JNICALL Java_com_player_xingfeng_multimedia_FFmpegNative_urlprotocolinfo
  (JNIEnv *env, jobject obj) {
    char info[40000] = {0};
    av_register_all();

    struct URLProtocol *pup = NULL;
    struct URLProtocol **p_temp = &pup;
    avio_enum_protocols((void **)p_temp, 0);
    while ((*p_temp) !=NULL) {
        sprintf(info, "%s[In ][%10s]\n", info, avio_enum_protocols((void **)p_temp, 0));
    }
    pup = NULL;

    avio_enum_protocols((void **)p_temp, 1);
    while ((*p_temp) !=NULL) {
        sprintf(info, "%s[Out ][%10s]\n", info, avio_enum_protocols((void **)p_temp, 1));
    }

    return env->NewStringUTF(info);
}

/*
 * Class:     com_player_xingfeng_multimedia_FFmpegNative
 * Method:    avformatinfo
 * Signature: ()Ljava/lang/String;
 */
JNIEXPORT jstring JNICALL Java_com_player_xingfeng_multimedia_FFmpegNative_avformatinfo
  (JNIEnv *env, jobject obj) {
    char info[40000] = {0};

    av_register_all();
    AVInputFormat *if_temp = av_iformat_next(NULL);
    AVOutputFormat *of_temp = av_oformat_next(NULL);

    while (if_temp != NULL) {
        sprintf(info, "%s[In ][%10s]\n", info, if_temp->name);
        if_temp=if_temp->next;
    }

    while (of_temp != NULL) {
        sprintf(info, "%s[Out ][%10s]\n", info, of_temp->name);
        of_temp=of_temp->next;
    }

    return env->NewStringUTF(info);
}

/*
 * Class:     com_player_xingfeng_multimedia_FFmpegNative
 * Method:    avcodecinfo
 * Signature: ()Ljava/lang/String;
 */
JNIEXPORT jstring JNICALL Java_com_player_xingfeng_multimedia_FFmpegNative_avcodecinfo
  (JNIEnv *env, jobject obj) {
    char info[40000] = {0};

    av_register_all();

    AVCodec *c_temp = av_codec_next(NULL);

    while (c_temp != NULL) {
        if (c_temp->decode != NULL) {
            sprintf(info, "%s[Dec]", info);
        } else {
            sprintf(info, "%s[Enc]", info);
        }
        switch (c_temp->type) {
            case AVMEDIA_TYPE_VIDEO:
                sprintf(info, "%s[VIDEO]", info);
                break;
            case AVMEDIA_TYPE_AUDIO:
                sprintf(info, "%s[AUDIO]", info);
                break;
            default:
                sprintf(info, "%s[OTHER]", info);
                break;
        }
        sprintf(info, "%s[%10s]\n", info, c_temp->name);
        c_temp=c_temp->next;
    }

    return env->NewStringUTF(info);
}

/*
 * Class:     com_player_xingfeng_multimedia_FFmpegNative
 * Method:    avfilterinfo
 * Signature: ()Ljava/lang/String;
 */
JNIEXPORT jstring JNICALL Java_com_player_xingfeng_multimedia_FFmpegNative_avfilterinfo
  (JNIEnv *env, jobject obj) {
    char info[40000] = { 0 };
    avfilter_register_all();
    AVFilter *f_temp = (AVFilter *)avfilter_next(NULL);
    int len = 0;
    while (f_temp != NULL){
        len = len + sizeof(f_temp->name);
        LOGI(LOG_TAG, "len:" + len);
        sprintf(info, "%s[%10s]\n", info, f_temp->name);
        f_temp=f_temp->next;
    }
    //LOGE("%s", info);

    return env->NewStringUTF(info);
}

/*
 * Class:     com_player_xingfeng_multimedia_FFmpegNative
 * Method:    configurationinfo
 * Signature: ()Ljava/lang/String;
 */
JNIEXPORT jstring JNICALL Java_com_player_xingfeng_multimedia_FFmpegNative_configurationinfo
  (JNIEnv *env, jobject obj) {
    char info[10000] = { 0 };
    av_register_all();

    sprintf(info, "%s\n", avcodec_configuration());

    //LOGE("%s", info);
    return env->NewStringUTF(info);
}


//Output FFmpeg's av_log()
void custom_log(void *ptr, int level, const char* fmt, va_list vl){
    FILE *fp=fopen("/storage/emulated/0/av_log.txt","a+");
    if(fp){
        vfprintf(fp,fmt,vl);
        fflush(fp);
        fclose(fp);
    }
}

JNIEXPORT jint JNICALL
Java_com_player_xingfeng_multimedia_FFmpegNative_decode(JNIEnv *env, jobject instance,
                                                        jstring inputPath, jstring outputPath) {
    const char *inPath = env->GetStringUTFChars(inputPath, NULL);
    const char *outPath = env->GetStringUTFChars(outputPath, NULL);

    // TODO
    env->ReleaseStringUTFChars(inputPath, inPath);
    env->ReleaseStringUTFChars(outputPath, outPath);

    AVFormatContext *pFormatCtx;
    int i, videoindex;
    AVCodecContext *pCodecCtx;
    AVCodec *pCodec;
    AVFrame *pFrame, *pFrameYUV;
    uint8_t *out_buffer;
    AVPacket *packet;
    int y_size;
    int ret, got_picture;
    struct SwsContext *img_convert_ctx;
    FILE *fp_yuv;
    int frame_cnt;
    clock_t time_start, time_finish;
    double time_duration = 0.0;

    char input_str[500] = {0};
    char output_str[500] ={0};
    char info[1000]={0};
    sprintf(input_str,"%s",env->GetStringUTFChars(inputPath, NULL));
    sprintf(output_str,"%s",env->GetStringUTFChars(outputPath, NULL));

    av_log_set_callback(custom_log);

    av_register_all();
    avformat_network_init();
    pFormatCtx = avformat_alloc_context();

    if (avformat_open_input(&pFormatCtx, input_str, NULL,NULL) != 0) {
        LOGE("Couldn't open input stream.\n");
        return -1;
    }

    if (avformat_find_stream_info(pFormatCtx, NULL) < 0) {
        LOGE("Couldn't find stream information.\n");
        return -1;
    }

    videoindex  -1;
    for (i = 0; i< pFormatCtx->nb_streams; i++) {
        if (pFormatCtx->streams[i]->codecpar->codec_type==AVMEDIA_TYPE_VIDEO) {
            videoindex = i;
            break;
        }
    }

    if (videoindex == -1) {
        LOGE("Couldn't find a video stream.\n");
        return  -1;
    }

    pCodec = avcodec_find_decoder(pFormatCtx->streams[videoindex]->codecpar->codec_id);
    pCodecCtx = avcodec_alloc_context3(pCodec);
    avcodec_parameters_to_context(pCodecCtx, pFormatCtx->streams[videoindex]->codecpar);

    if (pCodec == NULL) {
        LOGE("Couldn't find Codec.\n");
        return  -1;
    }
    if (avcodec_open2(pCodecCtx, pCodec, NULL) < 0) {
        LOGE("Couldn't find Codec.\n");
        return  -1;
    }

    pFrame = av_frame_alloc();
    pFrameYUV = av_frame_alloc();
    out_buffer = (unsigned char *)av_malloc(av_image_get_buffer_size(AV_PIX_FMT_YUV420P, pCodecCtx->width, pCodecCtx->height, 1));
    av_image_fill_arrays(pFrameYUV->data, pFrameYUV->linesize, out_buffer,
            AV_PIX_FMT_YUV420P, pCodecCtx->width, pCodecCtx->height, 1);

    packet = (AVPacket *)av_malloc(sizeof(AVPacket));

    img_convert_ctx = sws_getContext(pCodecCtx->width, pCodecCtx->height, pCodecCtx->pix_fmt,
            pCodecCtx->width, pCodecCtx->height, AV_PIX_FMT_YUV420P,  SWS_BICUBIC, NULL, NULL, NULL);

    sprintf(info,   "[Input     ]%s\n", input_str);
    sprintf(info, "%s[Output    ]%s\n",info,output_str);
    sprintf(info, "%s[Format    ]%s\n",info, pFormatCtx->iformat->name);
    sprintf(info, "%s[Codec     ]%s\n",info, pCodecCtx->codec_name);
    sprintf(info, "%s[Resolution]%dx%d\n",info, pCodecCtx->width,pCodecCtx->height);

    fp_yuv=fopen(output_str,"wb+");

    if(fp_yuv==NULL){
        printf("Cannot open output file.\n");
        return -1;
    }

    frame_cnt=0;
    time_start = clock();

    while(av_read_frame(pFormatCtx, packet)>=0){
        if(packet->stream_index==videoindex){
            ret = avcodec_decode_video2(pCodecCtx, pFrame, &got_picture, packet);
            if(ret < 0){
                LOGE("Decode Error.\n");
                return -1;
            }
            if(got_picture){
                sws_scale(img_convert_ctx, (const uint8_t* const*)pFrame->data, pFrame->linesize, 0, pCodecCtx->height,
                          pFrameYUV->data, pFrameYUV->linesize);

                y_size=pCodecCtx->width*pCodecCtx->height;
                fwrite(pFrameYUV->data[0],1,y_size,fp_yuv);    //Y
                fwrite(pFrameYUV->data[1],1,y_size/4,fp_yuv);  //U
                fwrite(pFrameYUV->data[2],1,y_size/4,fp_yuv);  //V
                //Output info
                char pictype_str[10]={0};
                switch(pFrame->pict_type){
                    case AV_PICTURE_TYPE_I:sprintf(pictype_str,"I");break;
                    case AV_PICTURE_TYPE_P:sprintf(pictype_str,"P");break;
                    case AV_PICTURE_TYPE_B:sprintf(pictype_str,"B");break;
                    default:sprintf(pictype_str,"Other");break;
                }
                LOGI("Frame Index: %5d. Type:%s",frame_cnt,pictype_str);
                frame_cnt++;
            }
        }
        av_free_packet(packet);
    }


    //flush decoder
    //FIX: Flush Frames remained in Codec
    while (1) {
        ret = avcodec_decode_video2(pCodecCtx, pFrame, &got_picture, packet);
        if (ret < 0)
            break;
        if (!got_picture)
            break;
        sws_scale(img_convert_ctx, (const uint8_t* const*)pFrame->data, pFrame->linesize, 0, pCodecCtx->height,
                  pFrameYUV->data, pFrameYUV->linesize);
        int y_size=pCodecCtx->width*pCodecCtx->height;
        fwrite(pFrameYUV->data[0],1,y_size,fp_yuv);    //Y
        fwrite(pFrameYUV->data[1],1,y_size/4,fp_yuv);  //U
        fwrite(pFrameYUV->data[2],1,y_size/4,fp_yuv);  //V
        //Output info
        char pictype_str[10]={0};
        switch(pFrame->pict_type){
            case AV_PICTURE_TYPE_I:sprintf(pictype_str,"I");break;
            case AV_PICTURE_TYPE_P:sprintf(pictype_str,"P");break;
            case AV_PICTURE_TYPE_B:sprintf(pictype_str,"B");break;
            default:sprintf(pictype_str,"Other");break;
        }
        LOGI("Frame Index: %5d. Type:%s",frame_cnt,pictype_str);
        frame_cnt++;
    }
    time_finish = clock();
    time_duration=(double)(time_finish - time_start);

    sprintf(info, "%s[Time      ]%fms\n",info,time_duration);
    sprintf(info, "%s[Count     ]%d\n",info,frame_cnt);

    sws_freeContext(img_convert_ctx);

    fclose(fp_yuv);

    av_frame_free(&pFrameYUV);
    av_frame_free(&pFrame);
    avcodec_close(pCodecCtx);
    avformat_close_input(&pFormatCtx);

    return 0;
}

/**
 * åªæ”¯æŒflvæœ¬åœ°æ–‡ä»¶çš„æ¨æµ,ç»æµ‹è¯•æ²¡æœ‰é—®é¢˜
 * @param env
 * @param obj
 * @param fileName_
 * @param pushUrl_
 * @return
 */
JNIEXPORT jint JNICALL
Java_com_player_xingfeng_multimedia_FFmpegNative_pushStream(JNIEnv *env, jobject obj,
                                                             jstring fileName_, jstring pushUrl_) {
    //æ‰€æœ‰ä»£ç æ‰§è¡Œä¹‹å‰è¦è°ƒç”¨av_register_allå’Œavformat_network_init
    //åˆå§‹åŒ–æ‰€æœ‰çš„å°è£…å’Œè§£å°è£… flv mp4 mp3 movã€‚ä¸åŒ…å«ç¼–ç å’Œè§£ç 
    av_register_all();

    //åˆå§‹åŒ–ç½‘ç»œåº“
    avformat_network_init();

    int ret = 0;
    //å°è£…ä¸Šä¸‹æ–‡
    AVFormatContext* ictx = NULL;
    AVFormatContext* octx = NULL;
    const char* iurl = env->GetStringUTFChars(fileName_, false);
    const char* ourl = env->GetStringUTFChars(pushUrl_, false);

    LOGD("rtmp://192.168.43.24/rtmplive/room");
    //æ‰“å¼€æ–‡ä»¶ï¼Œè§£å°æ–‡ä»¶å¤´
    ret = avformat_open_input(&ictx, iurl, NULL, NULL);
    if (ret != 0) {
        LOGD("avformat_open_input fail");
        return ret;
    }

    //è·å–éŸ³è§†é¢‘æµä¿¡æ¯,h264 flv
    ret = avformat_find_stream_info(ictx, NULL);
    if (ret != 0) {
        LOGD("avformat_find_stream_info fail");
        return ret;
    }

    //æ‰“å°åª’ä½“ä¿¡æ¯
    av_dump_format(ictx, 0, iurl, 0);

    //////////////////////////////

    //è¾“å‡ºæµ
    ret = avformat_alloc_output_context2(&octx, NULL, "flv", ourl);
    if (ret != 0) {
        LOGD("avformat_alloc_output_context2 fail");
        return ret;
    }

    LOGD("avformat_alloc_output_context2 success");

    //é…ç½®è¾“å‡ºæµ
    for (int i = 0; i < ictx->nb_streams; ++i)
    {
        //åˆ›å»ºæµ
        AVStream* ostream = avformat_new_stream(octx, avcodec_find_encoder(ictx->streams[i]->codecpar->codec_id));
        if (ostream == NULL)
            return -1;
        //å¤åˆ¶é…ç½®ä¿¡æ¯
        ret = avcodec_parameters_copy(ostream->codecpar, ictx->streams[i]->codecpar);
        if (ret != 0)
            return ret;
        ostream->codecpar->codec_tag = 0;//æ ‡è®°ä¸éœ€è¦é‡æ–°ç¼–è§£ç 
    }
    av_dump_format(octx, 0, ourl, 1);

    //////////////////////////////

    ret = avio_open(&octx->pb, ourl, AVIO_FLAG_WRITE);
    if (ret < 0) {
        LOGD("avio_open fail");
        return ret;
    } else {
        LOGD("avio_open success");
    }

    //å†™å…¥å¤´ä¿¡æ¯
    ret = avformat_write_header(octx, NULL);
    if (ret < 0) {
        LOGD("avformat_write_header fail");
        return ret;
    } else {
        LOGD("avformat_write_header success");
    }

    //æ¨æµæ¯ä¸€å¸§æ•°æ®
    AVPacket pkt;
    int64_t starttime = av_gettime();
    while (av_read_frame(ictx, &pkt) == 0)
    {
        //è®¡ç®—è½¬æ¢pts dts
        AVRational itime = ictx->streams[pkt.stream_index]->time_base;
        AVRational otime = octx->streams[pkt.stream_index]->time_base;
        pkt.pts = av_rescale_q_rnd(pkt.pts, itime, otime, (AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
        pkt.dts = av_rescale_q_rnd(pkt.dts, itime, otime, (AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
        pkt.duration = av_rescale_q_rnd(pkt.duration, itime, otime, (AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
        pkt.pos = -1;

        if (ictx->streams[pkt.stream_index]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO)
        {
            int64_t nowtime = av_gettime() - starttime;
            int64_t dts = pkt.dts * av_q2d(octx->streams[pkt.stream_index]->time_base) * 1000 * 1000;
            if(dts > nowtime)
                av_usleep(dts- nowtime);
        }

        ret = av_interleaved_write_frame(octx, &pkt);
        LOGD("av_interleaved_write_frame success");
        av_packet_unref(&pkt);
        if (ret < 0) {
            LOGD("av_interleaved_write_frame fail");
            return ret;
        } else {
            LOGD("av_interleaved_write_frame success");
        }
    }

    env->ReleaseStringUTFChars(fileName_, iurl);
    env->ReleaseStringUTFChars(pushUrl_, ourl);
    return 0;
}

/**
 * æ®è¯´å¯ä»¥æ”¯æŒflvåŠmp4æœ¬åœ°æ–‡ä»¶çš„æ¨æµ,ç»æµ‹è¯•flvæ²¡æœ‰é—®é¢˜,mp4è¿˜æ˜¯ğŸˆ¶é—®é¢˜ã€‚å¾…æœ‰æ—¶é—´å†ç ”ç©¶
 * @param env
 * @param obj
 * @param fileName_
 * @param pushUrl_
 * @return
 */
JNIEXPORT jint JNICALL
Java_com_player_xingfeng_multimedia_FFmpegNative_pushStream2(JNIEnv *env, jobject obj,
                                                            jstring fileName_, jstring pushUrl_) {
    int videoindex = -1;
    //æ‰€æœ‰ä»£ç æ‰§è¡Œä¹‹å‰è¦è°ƒç”¨av_register_allå’Œavformat_network_init
    //åˆå§‹åŒ–æ‰€æœ‰çš„å°è£…å’Œè§£å°è£… flv mp4 mp3 movã€‚ä¸åŒ…å«ç¼–ç å’Œè§£ç 
    av_register_all();

    //åˆå§‹åŒ–ç½‘ç»œåº“
    avformat_network_init();

    //ä½¿ç”¨çš„ç›¸å¯¹è·¯å¾„ï¼Œæ‰§è¡Œæ–‡ä»¶åœ¨binç›®å½•ä¸‹ã€‚test.mp4æ”¾åˆ°binç›®å½•ä¸‹å³å¯
    const char *inUrl = env->GetStringUTFChars(fileName_, false);
    //è¾“å‡ºçš„åœ°å€
    const char *outUrl = env->GetStringUTFChars(pushUrl_, false);

    //////////////////////////////////////////////////////////////////
    //                   è¾“å…¥æµå¤„ç†éƒ¨åˆ†
    /////////////////////////////////////////////////////////////////
    //æ‰“å¼€æ–‡ä»¶ï¼Œè§£å°è£… avformat_open_input
    //AVFormatContext **ps  è¾“å…¥å°è£…çš„ä¸Šä¸‹æ–‡ã€‚åŒ…å«æ‰€æœ‰çš„æ ¼å¼å†…å®¹å’Œæ‰€æœ‰çš„IOã€‚å¦‚æœæ˜¯æ–‡ä»¶å°±æ˜¯æ–‡ä»¶IOï¼Œç½‘ç»œå°±å¯¹åº”ç½‘ç»œIO
    //const char *url  è·¯å¾„
    //AVInputFormt * fmt å°è£…å™¨
    //AVDictionary ** options å‚æ•°è®¾ç½®
    AVFormatContext *ictx = NULL;

    AVOutputFormat *ofmt = NULL;

    //æ‰“å¼€æ–‡ä»¶ï¼Œè§£å°æ–‡ä»¶å¤´
    int ret = avformat_open_input(&ictx, inUrl, 0, NULL);
    if (ret < 0) {
        return avError(ret);
    }
    LOGD("avformat_open_input success!");
    //è·å–éŸ³é¢‘è§†é¢‘çš„ä¿¡æ¯ .h264 flv æ²¡æœ‰å¤´ä¿¡æ¯
    ret = avformat_find_stream_info(ictx, 0);
    if (ret != 0) {
        return avError(ret);
    }
    //æ‰“å°è§†é¢‘è§†é¢‘ä¿¡æ¯
    //0æ‰“å°æ‰€æœ‰  inUrl æ‰“å°æ—¶å€™æ˜¾ç¤ºï¼Œ
    av_dump_format(ictx, 0, inUrl, 0);

    //////////////////////////////////////////////////////////////////
    //                   è¾“å‡ºæµå¤„ç†éƒ¨åˆ†
    /////////////////////////////////////////////////////////////////
    AVFormatContext * octx = NULL;
    //å¦‚æœæ˜¯è¾“å…¥æ–‡ä»¶ flvå¯ä»¥ä¸ä¼ ï¼Œå¯ä»¥ä»æ–‡ä»¶ä¸­åˆ¤æ–­ã€‚å¦‚æœæ˜¯æµåˆ™å¿…é¡»ä¼ 
    //åˆ›å»ºè¾“å‡ºä¸Šä¸‹æ–‡
    ret = avformat_alloc_output_context2(&octx, NULL, "flv", outUrl);
    if (ret < 0) {
        return avError(ret);
    }
    LOGD("avformat_alloc_output_context2 success!");

    ofmt = octx->oformat;
    //cout << "nb_streams  " << ictx->nb_streams << endl;
    int i;
    //for (i = 0; i < ictx->nb_streams; i++) {
    //  cout << "i " << i <<"  "<< ictx->nb_streams<< endl;
    //  AVStream *in_stream = ictx->streams[i];
    //  AVCodec *codec = avcodec_find_decoder(in_stream->codecpar->codec_id);
    //  AVStream *out_stream = avformat_new_stream(octx, codec);
    //  if (!out_stream) {
    //      printf("Failed allocating output stream\n");
    //      ret = AVERROR_UNKNOWN;
    //  }
    //  AVCodecContext *pCodecCtx = avcodec_alloc_context3(codec);
    //  ret = avcodec_parameters_to_context(pCodecCtx, in_stream->codecpar);
    //  if (ret < 0) {
    //      printf("Failed to copy context input to output stream codec context\n");
    //  }
    //  pCodecCtx->codec_tag = 0;
    //  if (octx->oformat->flags & AVFMT_GLOBALHEADER) {
    //      pCodecCtx->flags |= CODEC_FLAG_GLOBAL_HEADER;
    //  }
    //  ret = avcodec_parameters_from_context(out_stream->codecpar, pCodecCtx);
    //  if (ret < 0) {
    //      printf("Failed to copy context input to output stream codec context\n");
    //  }
    //}

    for (i = 0; i < ictx->nb_streams; i++) {

        //è·å–è¾“å…¥è§†é¢‘æµ
        AVStream *in_stream = ictx->streams[i];
        //ä¸ºè¾“å‡ºä¸Šä¸‹æ–‡æ·»åŠ éŸ³è§†é¢‘æµï¼ˆåˆå§‹åŒ–ä¸€ä¸ªéŸ³è§†é¢‘æµå®¹å™¨ï¼‰
        AVStream *out_stream = avformat_new_stream(octx, avcodec_find_encoder(in_stream->codecpar->codec_id));
        if (!out_stream) {
            printf("æœªèƒ½æˆåŠŸæ·»åŠ éŸ³è§†é¢‘æµ\n");
            ret = AVERROR_UNKNOWN;
        }


        AVCodecContext *codec_ctx = avcodec_alloc_context3(avcodec_find_encoder(in_stream->codecpar->codec_id));
        ret = avcodec_parameters_to_context(codec_ctx, in_stream->codecpar);
        if (ret < 0){
            printf("Failed to copy in_stream codecpar to codec context\n");
            //goto end;
        }

        codec_ctx->codec_tag = 0;
        if (octx->oformat->flags & AVFMT_GLOBALHEADER)
            codec_ctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;

        ret = avcodec_parameters_from_context(out_stream->codecpar, codec_ctx);
        if (ret < 0) {
            LOGD("copy ç¼–è§£ç å™¨ä¸Šä¸‹æ–‡å¤±è´¥");
        }

//        //å°†è¾“å…¥ç¼–è§£ç å™¨ä¸Šä¸‹æ–‡ä¿¡æ¯ copy ç»™è¾“å‡ºç¼–è§£ç å™¨ä¸Šä¸‹æ–‡
//        //ret = avcodec_copy_context(out_stream->codec, in_stream->codec);
//        ret = avcodec_parameters_copy(out_stream->codecpar, in_stream->codecpar);
//        //ret = avcodec_parameters_from_context(out_stream->codecpar, in_stream->codec);
//        //ret = avcodec_parameters_to_context(out_stream->codec, in_stream->codecpar);
//        if (ret < 0) {
//            printf("copy ç¼–è§£ç å™¨ä¸Šä¸‹æ–‡å¤±è´¥\n");
//        }
//
//        out_stream->codecpar->codec_tag = 0;
//        if (octx->oformat->flags & AVFMT_GLOBALHEADER) {
//            out_stream->codecpar->flags = out_stream->codec->flags | CODEC_FLAG_GLOBAL_HEADER;
//        }
    }

    //è¾“å…¥æµæ•°æ®çš„æ•°é‡å¾ªç¯
    for (i = 0; i < ictx->nb_streams; i++) {
        if (ictx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
            videoindex = i;
            break;
        }
    }

    av_dump_format(octx, 0, outUrl, 1);

    //////////////////////////////////////////////////////////////////
    //                   å‡†å¤‡æ¨æµ
    /////////////////////////////////////////////////////////////////

    //æ‰“å¼€IO
    ret = avio_open(&octx->pb, outUrl, AVIO_FLAG_WRITE);
    if (ret < 0) {
        avError(ret);
    }

    //å†™å…¥å¤´éƒ¨ä¿¡æ¯
    ret = avformat_write_header(octx, 0);
    if (ret < 0) {
        avError(ret);
    }
    LOGD("avformat_write_header Success!");
    //æ¨æµæ¯ä¸€å¸§æ•°æ®
    //int64_t pts  [ pts*(num/den)  ç¬¬å‡ ç§’æ˜¾ç¤º]
    //int64_t dts  è§£ç æ—¶é—´ [På¸§(ç›¸å¯¹äºä¸Šä¸€å¸§çš„å˜åŒ–) Iå¸§(å…³é”®å¸§ï¼Œå®Œæ•´çš„æ•°æ®) Bå¸§(ä¸Šä¸€å¸§å’Œä¸‹ä¸€å¸§çš„å˜åŒ–)]  æœ‰äº†Bå¸§å‹ç¼©ç‡æ›´é«˜ã€‚
    //uint8_t *data
    //int size
    //int stream_index
    //int flag
    AVPacket pkt;
    //è·å–å½“å‰çš„æ—¶é—´æˆ³  å¾®å¦™
    long long start_time = av_gettime();
    long long frame_index = 0;
    while (1) {
        //è¾“å…¥è¾“å‡ºè§†é¢‘æµ
        AVStream *in_stream, *out_stream;
        //è·å–è§£ç å‰æ•°æ®
        ret = av_read_frame(ictx, &pkt);
        if (ret < 0) {
            break;
        }

        /*
        PTSï¼ˆPresentation Time Stampï¼‰æ˜¾ç¤ºæ’­æ”¾æ—¶é—´
        DTSï¼ˆDecoding Time Stampï¼‰è§£ç æ—¶é—´
        */
        //æ²¡æœ‰æ˜¾ç¤ºæ—¶é—´ï¼ˆæ¯”å¦‚æœªè§£ç çš„ H.264 ï¼‰
        if (pkt.pts == AV_NOPTS_VALUE) {
            //AVRational time_baseï¼šæ—¶åŸºã€‚é€šè¿‡è¯¥å€¼å¯ä»¥æŠŠPTSï¼ŒDTSè½¬åŒ–ä¸ºçœŸæ­£çš„æ—¶é—´ã€‚
            AVRational time_base1 = ictx->streams[videoindex]->time_base;

            //è®¡ç®—ä¸¤å¸§ä¹‹é—´çš„æ—¶é—´
            /*
            r_frame_rate åŸºæµå¸§é€Ÿç‡  ï¼ˆä¸æ˜¯å¤ªæ‡‚ï¼‰
            av_q2d è½¬åŒ–ä¸ºdoubleç±»å‹
            */
            int64_t calc_duration = (double)AV_TIME_BASE / av_q2d(ictx->streams[videoindex]->r_frame_rate);

            //é…ç½®å‚æ•°
            pkt.pts = (double)(frame_index*calc_duration) / (double)(av_q2d(time_base1)*AV_TIME_BASE);
            pkt.dts = pkt.pts;
            pkt.duration = (double)calc_duration / (double)(av_q2d(time_base1)*AV_TIME_BASE);
        }

        //å»¶æ—¶
        if (pkt.stream_index == videoindex) {
            AVRational time_base = ictx->streams[videoindex]->time_base;
            AVRational time_base_q = { 1,AV_TIME_BASE };
            //è®¡ç®—è§†é¢‘æ’­æ”¾æ—¶é—´
            int64_t pts_time = av_rescale_q(pkt.dts, time_base, time_base_q);
            //è®¡ç®—å®é™…è§†é¢‘çš„æ’­æ”¾æ—¶é—´
            int64_t now_time = av_gettime() - start_time;

            AVRational avr = ictx->streams[videoindex]->time_base;
            //cout << avr.num << " " << avr.den << "  "<<pkt.dts <<"  "<<pkt.pts<<"   "<< pts_time <<endl;
            if (pts_time > now_time) {
                //ç¡çœ ä¸€æ®µæ—¶é—´ï¼ˆç›®çš„æ˜¯è®©å½“å‰è§†é¢‘è®°å½•çš„æ’­æ”¾æ—¶é—´ä¸å®é™…æ—¶é—´åŒæ­¥ï¼‰
                av_usleep((unsigned int)(pts_time - now_time));
            }
        }

        in_stream = ictx->streams[pkt.stream_index];
        out_stream = octx->streams[pkt.stream_index];

        //è®¡ç®—å»¶æ—¶åï¼Œé‡æ–°æŒ‡å®šæ—¶é—´æˆ³
        pkt.pts = av_rescale_q_rnd(pkt.pts, in_stream->time_base, out_stream->time_base,(AVRounding) (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
        pkt.dts = av_rescale_q_rnd(pkt.dts, in_stream->time_base, out_stream->time_base, (AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
        pkt.duration = (int)av_rescale_q(pkt.duration, in_stream->time_base, out_stream->time_base);
        //å­—èŠ‚æµçš„ä½ç½®ï¼Œ-1 è¡¨ç¤ºä¸çŸ¥é“å­—èŠ‚æµä½ç½®
        pkt.pos = -1;

        if (pkt.stream_index == videoindex) {
            LOGD("Send %8d video frames to output URL\n", frame_index);
            frame_index++;
        }

        //å‘è¾“å‡ºä¸Šä¸‹æ–‡å‘é€ï¼ˆå‘åœ°å€æ¨é€ï¼‰
        ret = av_interleaved_write_frame(octx, &pkt);

        if (ret < 0) {
            printf("å‘é€æ•°æ®åŒ…å‡ºé”™\n");
            break;
        }

        //é‡Šæ”¾
        av_free_packet(&pkt);
    }
    return 0;
}

const char *filters_descr = "drawbox=x=100:y=100:w=100:h=100:color=pink@0.5";

int getCodecContext(AVCodecParameters *codecpar, AVCodecContext **avCodecContext) {
    AVCodec *dec = avcodec_find_decoder(codecpar->codec_id);
    if (!dec) {
        LOGD("can not find decoder");
        return -1;
    }

    *avCodecContext = avcodec_alloc_context3(dec);
    if (!*avCodecContext) {
        LOGD("can not alloc new decodecctx");
        return -1;
    }

    if (avcodec_parameters_to_context(*avCodecContext, codecpar) < 0) {
        avcodec_free_context(avCodecContext);
        *avCodecContext = NULL;
        LOGD("can not fill decodecctx");
        return -1;
    }

    if (avcodec_open2(*avCodecContext, dec, 0) != 0) {
        LOGD("cant not open audio strames");
        avcodec_free_context(avCodecContext);
        *avCodecContext = NULL;
        return -1;
    }
    return 0;
}

/**
 *
 * @param env
 * @param instance
 * @param url
 * @param surface
 * @return
 */
JNIEXPORT void JNICALL
Java_com_player_xingfeng_multimedia_FFmpegNative_play(JNIEnv *env, jobject instance,
        jstring url_, jobject surface) {
    const char *url = env->GetStringUTFChars(url_, 0);

    AVFormatContext *pFormatCtx = NULL;
    AVCodecContext *pCodecCtx = NULL;

    AVFilterContext *buffersink_ctx = NULL;
    AVFilterContext *buffersrc_ctx = NULL;
    AVFilterGraph *filter_graph = NULL;

    //-----------------------------AVCodecContext init start----------------------------
    av_register_all();
    avfilter_register_all();//
    pFormatCtx = avformat_alloc_context();

    // Open video file
    if (avformat_open_input(&pFormatCtx, url, NULL, NULL) != 0) {

        LOGD("Couldn't open url:%s\n", url);
        return; // Couldn't open file
    }

    // Retrieve stream information
    if (avformat_find_stream_info(pFormatCtx, NULL) < 0) {
        LOGD("Couldn't find stream information.");
        return;
    }

    // Find the first video stream
    int videoStream = -1, i;
    for (i = 0; i < pFormatCtx->nb_streams; i++) {
        if (pFormatCtx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO
            && videoStream < 0) {
            videoStream = i;
        }
    }
    if (videoStream == -1) {
        LOGD("Didn't find a video stream.");
        return; // Didn't find a video stream
    }

    if (getCodecContext(pFormatCtx->streams[videoStream]->codecpar, &pCodecCtx) != 0) {
        LOGD("Didn't get CodecContext.");
        return;
    }
    //-----------------------------AVCodecContext init end-------------------------------

    //------------------------------filter init start------------------------------------
    char args[512];
    AVFilter *buffersrc = avfilter_get_by_name("buffer");
    AVFilter *buffersink = avfilter_get_by_name("buffersink");//æ–°ç‰ˆçš„ffmpegåº“å¿…é¡»ä¸ºbuffersink
    AVFilterInOut *outputs = avfilter_inout_alloc();
    AVFilterInOut *inputs = avfilter_inout_alloc();

    enum AVPixelFormat pix_fmts[] = {AV_PIX_FMT_YUV420P, AV_PIX_FMT_NONE};

    filter_graph = avfilter_graph_alloc();

    /* buffer video source: the decoded frames from the decoder will be inserted here. */
    snprintf(args, sizeof(args),
             "video_size=%dx%d:pix_fmt=%d:time_base=%d/%d:pixel_aspect=%d/%d",
             pCodecCtx->width, pCodecCtx->height, pCodecCtx->pix_fmt,
             pFormatCtx->streams[videoStream]->time_base.num,
             pFormatCtx->streams[videoStream]->time_base.den,
             pCodecCtx->sample_aspect_ratio.num, pCodecCtx->sample_aspect_ratio.den);

    if (avfilter_graph_create_filter(&buffersrc_ctx, buffersrc, "in",
                                     args, NULL, filter_graph) < 0) {
        LOGD("Cannot create buffer source\n");
        return;
    }
    AVBufferSinkParams *buffersink_params = av_buffersink_params_alloc();
    buffersink_params->pixel_fmts = pix_fmts;
    if (avfilter_graph_create_filter(&buffersink_ctx, buffersink, "out",
                                     NULL, buffersink_params, filter_graph) < 0) {
        LOGD("Cannot create buffer sink\n");
        return;
    }
    av_free(buffersink_params);

    /* Endpoints for the filter graph. */
    outputs->name = av_strdup("in");
    outputs->filter_ctx = buffersrc_ctx;
    outputs->pad_idx = 0;
    outputs->next = NULL;

    inputs->name = av_strdup("out");
    inputs->filter_ctx = buffersink_ctx;
    inputs->pad_idx = 0;
    inputs->next = NULL;

    if ((avfilter_graph_parse_ptr(filter_graph, filters_descr,
                                  &inputs, &outputs, NULL)) < 0) {
        LOGD("Cannot avfilter_graph_parse_ptr\n");
        return;
    }

    if ((avfilter_graph_config(filter_graph, NULL)) < 0) {
        LOGD("Cannot avfilter_graph_config\n");
        return;
    }
    //------------------------------filter init end------------------------------------

    //------------------------------window init start-----------------------------------
    // è·å–native window
    ANativeWindow *nativeWindow = ANativeWindow_fromSurface(env, surface);

    // è·å–è§†é¢‘å®½é«˜
    int videoWidth = pCodecCtx->width;
    int videoHeight = pCodecCtx->height;

    // è®¾ç½®native windowçš„bufferå¤§å°,å¯è‡ªåŠ¨æ‹‰ä¼¸
    ANativeWindow_setBuffersGeometry(nativeWindow, videoWidth, videoHeight,
                                     WINDOW_FORMAT_RGBA_8888);
    ANativeWindow_Buffer windowBuffer;
    //------------------------------window init end-----------------------------------


    //------------------------------get data-----------------------------------


    // ç”¨äºæ¸²æŸ“
    AVFrame *pFrameRGBA = av_frame_alloc();

    // Determine required buffer size and allocate buffer
    // bufferä¸­æ•°æ®å°±æ˜¯ç”¨äºæ¸²æŸ“çš„,ä¸”æ ¼å¼ä¸ºRGBA
    int numBytes = av_image_get_buffer_size(AV_PIX_FMT_RGBA, pCodecCtx->width, pCodecCtx->height,
                                            1);
    uint8_t *buffer = (uint8_t *) av_malloc(numBytes * sizeof(uint8_t));
    av_image_fill_arrays(pFrameRGBA->data, pFrameRGBA->linesize, buffer, AV_PIX_FMT_RGBA,
                         pCodecCtx->width, pCodecCtx->height, 1);

    // ç”±äºè§£ç å‡ºæ¥çš„å¸§æ ¼å¼ä¸æ˜¯RGBAçš„,åœ¨æ¸²æŸ“ä¹‹å‰éœ€è¦è¿›è¡Œæ ¼å¼è½¬æ¢
    SwsContext *sws_ctx = sws_getContext(pCodecCtx->width,
                                         pCodecCtx->height,
                                         pCodecCtx->pix_fmt,
                                         pCodecCtx->width,
                                         pCodecCtx->height,
                                         AV_PIX_FMT_RGBA,
                                         SWS_BILINEAR,
                                         NULL,
                                         NULL,
                                         NULL);

    AVPacket *packet = av_packet_alloc();
    int count = 0;
    while (av_read_frame(pFormatCtx, packet) == 0) {
        // Is this a packet from the video stream?
        if (packet->stream_index == videoStream) {
            // Decode video frame
            if (avcodec_send_packet(pCodecCtx, packet) != 0) {
                break;
            }

            AVFrame *pFrame = av_frame_alloc();

            while (avcodec_receive_frame(pCodecCtx, pFrame) == 0) {
                // lock native window buffer
                ANativeWindow_lock(nativeWindow, &windowBuffer, 0);

                //for AVfilter start
                pFrame->pts = av_frame_get_best_effort_timestamp(pFrame);
                //* push the decoded frame into the filtergraph
                if (av_buffersrc_add_frame(buffersrc_ctx, pFrame) == 0) {
                    av_buffersink_get_frame(buffersink_ctx, pFrame);
                } else{
                    LOGD("Could not av_buffersrc_add_frame");
                }
                // æ ¼å¼è½¬æ¢
                sws_scale(sws_ctx, (uint8_t const *const *) pFrame->data,
                          pFrame->linesize, 0, pCodecCtx->height,
                          pFrameRGBA->data, pFrameRGBA->linesize);

                // è·å–stride
                uint8_t *dst = (uint8_t *) windowBuffer.bits;
                int dstStride = windowBuffer.stride * 4;
                uint8_t *src = (pFrameRGBA->data[0]);
                int srcStride = pFrameRGBA->linesize[0];

                // ç”±äºwindowçš„strideå’Œå¸§çš„strideä¸åŒ,å› æ­¤éœ€è¦é€è¡Œå¤åˆ¶
                int h;
                for (h = 0; h < videoHeight; h++) {
                    memcpy(dst + h * dstStride, src + h * srcStride, srcStride);
                }
                ANativeWindow_unlockAndPost(nativeWindow);

                count++;
                LOGD("è§£ç æ¸²æŸ“%då¸§", count);
            }
            av_frame_free(&pFrame);
            av_free(pFrame);
        }
    }


    if (nativeWindow) {
       ANativeWindow_release(nativeWindow);
    }
    av_packet_free(&packet);
    sws_freeContext(sws_ctx);

    avfilter_inout_free(&outputs);
    av_free(outputs);
    avfilter_inout_free(&inputs);
    av_free(inputs);

    av_free(buffer);
    av_frame_free(&pFrameRGBA);
    av_free(pFrameRGBA);

    avfilter_graph_free(&filter_graph); //for avfilter
    // Close the codecs
    avcodec_close(pCodecCtx);
    avcodec_free_context(&pCodecCtx);
    pCodecCtx = NULL;

    // Close the video file
    avformat_close_input(&pFormatCtx);
    avformat_free_context(pFormatCtx);
    pFormatCtx = NULL;

    env->ReleaseStringUTFChars(url_, url);
}